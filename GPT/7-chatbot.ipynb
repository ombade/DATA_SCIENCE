{"cells":[{"cell_type":"markdown","metadata":{"id":"2dLdwEIy91QX"},"source":["# The Chat Format\n","\n","In this notebook, you will explore how you can utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors.\n","\n","## Setup"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7N8bvwlT98KX"},"outputs":[],"source":["import os\n","import openai\n","# from dotenv import load_dotenv, find_dotenv\n","# _ = load_dotenv(find_dotenv()) # read local .env file\n","\n","openai.api_key  = ('OPENAI_API_KEY')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"OwMBRMRp9_ze"},"outputs":[],"source":["def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=0, # this is the degree of randomness of the model's output\n","    )\n","    return response.choices[0].message[\"content\"]\n","\n","def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temperature, # this is the degree of randomness of the model's output\n","    )\n","#     print(str(response.choices[0].message))\n","    return response.choices[0].message[\"content\"]"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"sMGK0pze-CsG"},"outputs":[],"source":["messages =  [  \n","{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    \n","{'role':'user', 'content':'tell me a joke'},   \n","{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n","{'role':'user', 'content':'I don\\'t know'}  ]"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"6NFd2sGA-EgV"},"outputs":[{"ename":"AuthenticationError","evalue":"Incorrect API key provided: OPENAI_A**_KEY. You can find your API key at https://platform.openai.com/account/api-keys.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Om Bade\\Downloads\\chatgpt-prompt-engineering-main\\chatgpt-prompt-engineering-main\\7-chatbot.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response \u001b[39m=\u001b[39m get_completion_from_messages(messages, temperature\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n","\u001b[1;32mc:\\Users\\Om Bade\\Downloads\\chatgpt-prompt-engineering-main\\chatgpt-prompt-engineering-main\\7-chatbot.ipynb Cell 5\u001b[0m in \u001b[0;36mget_completion_from_messages\u001b[1;34m(messages, model, temperature)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_completion_from_messages\u001b[39m(messages, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         temperature\u001b[39m=\u001b[39;49mtemperature, \u001b[39m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#     print(str(response.choices[0].message))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Om%20Bade/Downloads/chatgpt-prompt-engineering-main/chatgpt-prompt-engineering-main/7-chatbot.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n","File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n","File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n","File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    705\u001b[0m         ),\n\u001b[0;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Om Bade\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\openai\\api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    765\u001b[0m     )\n\u001b[0;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n","\u001b[1;31mAuthenticationError\u001b[0m: Incorrect API key provided: OPENAI_A**_KEY. You can find your API key at https://platform.openai.com/account/api-keys."]}],"source":["response = get_completion_from_messages(messages, temperature=1)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uBuXUMtD-F_C"},"outputs":[],"source":["messages =  [  \n","{'role':'system', 'content':'You are friendly chatbot.'},    \n","{'role':'user', 'content':'Hi, my name is Isa'}  ]\n","response = get_completion_from_messages(messages, temperature=1)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-t2Fkykz-HpK"},"outputs":[],"source":["messages =  [  \n","{'role':'system', 'content':'You are friendly chatbot.'},    \n","{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n","response = get_completion_from_messages(messages, temperature=1)\n","print(response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQp3kZHr-JYL"},"outputs":[],"source":["messages =  [  \n","{'role':'system', 'content':'You are friendly chatbot.'},\n","{'role':'user', 'content':'Hi, my name is Isa'},\n","{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\\n","Is there anything I can help you with today?\"},\n","{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]\n","response = get_completion_from_messages(messages, temperature=1)\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"YGfYQGtK-Mb9"},"source":["# OrderBot\n","We can automate the collection of user prompts and assistant responses to build a  OrderBot. The OrderBot will take orders at a pizza restaurant. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjeMn4Ae-N8t"},"outputs":[],"source":["def collect_messages(_):\n","    prompt = inp.value_input\n","    inp.value = ''\n","    context.append({'role':'user', 'content':f\"{prompt}\"})\n","    response = get_completion_from_messages(context) \n","    context.append({'role':'assistant', 'content':f\"{response}\"})\n","    panels.append(\n","        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n","    panels.append(\n","        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n"," \n","    return pn.Column(*panels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZOhIArq-PsK"},"outputs":[],"source":["import panel as pn  # GUI\n","pn.extension()\n","\n","panels = [] # collect display \n","\n","context = [ {'role':'system', 'content':\"\"\"\n","You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n","You first greet the customer, then collects the order, \\\n","and then asks if it's a pickup or delivery. \\\n","You wait to collect the entire order, then summarize it and check for a final \\\n","time if the customer wants to add anything else. \\\n","If it's a delivery, you ask for an address. \\\n","Finally you collect the payment.\\\n","Make sure to clarify all options, extras and sizes to uniquely \\\n","identify the item from the menu.\\\n","You respond in a short, very conversational friendly style. \\\n","The menu includes \\\n","pepperoni pizza  12.95, 10.00, 7.00 \\\n","cheese pizza   10.95, 9.25, 6.50 \\\n","eggplant pizza   11.95, 9.75, 6.75 \\\n","fries 4.50, 3.50 \\\n","greek salad 7.25 \\\n","Toppings: \\\n","extra cheese 2.00, \\\n","mushrooms 1.50 \\\n","sausage 3.00 \\\n","canadian bacon 3.50 \\\n","AI sauce 1.50 \\\n","peppers 1.00 \\\n","Drinks: \\\n","coke 3.00, 2.00, 1.00 \\\n","sprite 3.00, 2.00, 1.00 \\\n","bottled water 5.00 \\\n","\"\"\"} ]  # accumulate messages\n","\n","\n","inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text hereâ€¦')\n","button_conversation = pn.widgets.Button(name=\"Chat!\")\n","\n","interactive_conversation = pn.bind(collect_messages, button_conversation)\n","\n","dashboard = pn.Column(\n","    inp,\n","    pn.Row(button_conversation),\n","    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",")\n","\n","dashboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ygfqeKq8-TWB"},"outputs":[],"source":["messages =  context.copy()\n","messages.append(\n","{'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\\n"," The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},    \n",")\n"," #The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},    \n","\n","response = get_completion_from_messages(messages, temperature=0)\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"ZdAebAqa-WMH"},"source":["## Try experimenting on your own!\n","\n","You can modify the menu or instructions to create your own orderbot!"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPUB/l//BFK5z5KaeV64uDe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"}},"nbformat":4,"nbformat_minor":0}
