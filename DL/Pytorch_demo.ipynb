{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCvlYUCRkfMa"
      },
      "source": [
        "# PyTorch Basics: Tensors & Gradients\n",
        "\n",
        "<img src=\"data:image/png;base64,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\" width=\"600\"\n",
        "     height=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "  PyTorch is an open-source machine learning framework that is primarily used for developing and training deep learning models. It was developed by Facebook's AI Research Lab and released in 2016. PyTorch provides a flexible and dynamic approach to building neural networks, making it a popular choice among researchers and developers.\n",
        "\n",
        "The framework is built on a dynamic computational graph concept, which means that the graph is built and modified on-the-fly as the program runs. This allows for more intuitive and flexible model development, as you can use standard Python control flow statements and debug the model easily.\n",
        "\n",
        "PyTorch supports automatic differentiation, which enables efficient computation of gradients for training neural networks using backpropagation. It provides a rich set of tools and libraries for tasks such as data loading, model building, optimization, and evaluation.\n",
        "\n",
        "One of the key advantages of PyTorch is its support for GPU acceleration, allowing you to train models on GPUs to significantly speed up computations. It also has a large and active community, which means there are plenty of resources, tutorials, and pre-trained models available.\n",
        "\n",
        "PyTorch is often compared to TensorFlow, another popular deep learning framework. While TensorFlow focuses more on static computation graphs, PyTorch emphasizes dynamic computation graphs. This fundamental difference in design philosophy gives PyTorch an edge when it comes to flexibility and ease of use.\n",
        "\n",
        "Overall, PyTorch is widely used in the research community and is gaining popularity in industry applications as well. It provides a powerful and user-friendly platform for building and training deep learning models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5zufMMCkfMo"
      },
      "source": [
        "## installation\n",
        "\n",
        "installation instructions here: https://pytorch.org ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmnQZPSxkfMp"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P18JcOiokfMr"
      },
      "source": [
        "Let's import the `torch` module to get started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DGo8nxo7kfMs"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqVgPkfKkfMt"
      },
      "source": [
        "## Tensors\n",
        "\n",
        "At its core, PyTorch is a library for processing tensors. A tensor is a number, vector, matrix, or any n-dimensional array. Let's create a tensor with a single number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUtf5elpkfMv",
        "outputId": "c6213e23-bfa8-4898-94cd-7c22e0ac5e33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Number\n",
        "t1 = torch.tensor(4.)\n",
        "t1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIB1GJlakfMw"
      },
      "source": [
        "`4.` is a shorthand for `4.0`. It is used to indicate to Python (and PyTorch) that you want to create a floating-point number. We can verify this by checking the `dtype` attribute of our tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jz-QWm7NkfMx",
        "outputId": "0791321f-f126-429a-a9be-85df0cf7ce27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "t1.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd_-gGY-kfMy"
      },
      "source": [
        "Let's try creating more complex tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIn2pRzLkfMz",
        "outputId": "fa01602b-46be-48a7-d11a-be37901ecaf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Vector\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KdQsBZqukfM0",
        "outputId": "b37bfbe3-504f-4cae-c872-2796ccf09cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Matrix\n",
        "t3 = torch.tensor([[5., 6],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "t3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yZHb2E5kfM0",
        "outputId": "1253aafb-43a5-40c2-f5ae-7660cec39235",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11., 12., 13.],\n",
              "         [13., 14., 15.]],\n",
              "\n",
              "        [[15., 16., 17.],\n",
              "         [17., 18., 19.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# 3-dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [[11, 12, 13],\n",
        "     [13, 14, 15]],\n",
        "    [[15, 16, 17],\n",
        "     [17, 18, 19.]]])\n",
        "t4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS8_bliOkfM1"
      },
      "source": [
        "Tensors can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUx8_FbXkfM1",
        "outputId": "81fb8513-ad30-4f42-95a7-eb21bcea9db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "print(t1)\n",
        "t1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeRzfymnkfM2",
        "outputId": "91f26c00-48c3-40b8-db6c-0580162c948b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "print(t2)\n",
        "t2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXvIYzuxkfM2",
        "outputId": "6ca810a0-d20c-49f2-8a2c-363c5521f499",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "print(t3)\n",
        "t3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5okplTtkfM3",
        "outputId": "6d16bb62-fe42-47d8-a26a-6324a2ecbb48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[11., 12., 13.],\n",
            "         [13., 14., 15.]],\n",
            "\n",
            "        [[15., 16., 17.],\n",
            "         [17., 18., 19.]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "print(t4)\n",
        "t4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NOD0XtokfM3"
      },
      "source": [
        "Note that it's not possible to create tensors with an improper shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZiaIlFtWkfM4",
        "outputId": "aba02c1a-bcd8-4536-cf47-ee7980aa61c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-83912cf67c5e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m t5 = torch.tensor([[5., 6, 11], \n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    [9, 10]])\n\u001b[1;32m      5\u001b[0m \u001b[0mt5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: expected sequence of length 3 at dim 1 (got 2)"
          ]
        }
      ],
      "source": [
        "# Matrix\n",
        "t5 = torch.tensor([[5., 6, 11],\n",
        "                   [7, 8],\n",
        "                   [9, 10]])\n",
        "t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWBdhA9kkfM4"
      },
      "source": [
        "A `ValueError` is thrown because the lengths of the rows `[5., 6, 11]` and `[7, 8]` don't match."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7cKJKdakfM5"
      },
      "source": [
        "## Tensor operations and gradients\n",
        "\n",
        "We can combine tensors with the usual arithmetic operations. Let's look at an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj6TfIlokfM5",
        "outputId": "628fca2f-675f-4c9a-d8a2-323ced3d93e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4., requires_grad=True)\n",
        "b = torch.tensor(5., requires_grad=True)\n",
        "x, w, b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVZlcATrkfM5"
      },
      "source": [
        "We've created three tensors: `x`, `w`, and `b`, all numbers. `w` and `b` have an additional parameter `requires_grad` set to `True`. We'll see what it does in just a moment.\n",
        "\n",
        "Let's create a new tensor `y` by combining these tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKcsAaE0kfM6",
        "outputId": "d12880cc-a732-4b01-da26-c7e501796e99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Arithmetic operations\n",
        "y = w * x + b\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNV4U0-OkfM6"
      },
      "source": [
        "As expected, `y` is a tensor with the value `3 * 4 + 5 = 17`. What makes PyTorch unique is that we can automatically compute the derivative of `y` w.r.t. the tensors that have `requires_grad` set to `True` i.e. w and b. This feature of PyTorch is called _autograd_ (automatic gradients).\n",
        "\n",
        "To compute the derivatives, we can invoke the `.backward` method on our result `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RVH2vHCkfM6"
      },
      "outputs": [],
      "source": [
        "# Compute derivatives\n",
        "y.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHyHerbekfM7"
      },
      "source": [
        "The derivatives of `y` with respect to the input tensors are stored in the `.grad` property of the respective tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zTB-VUqkfM7",
        "outputId": "6d5d0032-6db9-4042-e8f3-c14e378bb704",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx: None\n",
            "dy/dw: tensor(3.)\n",
            "dy/db: tensor(1.)\n"
          ]
        }
      ],
      "source": [
        "# Display gradients\n",
        "print('dy/dx:', x.grad)\n",
        "print('dy/dw:', w.grad)\n",
        "print('dy/db:', b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvGfw6PJkfM7"
      },
      "source": [
        "As expected, `dy/dw` has the same value as `x`, i.e., `3`, and `dy/db` has the value `1`. Note that `x.grad` is `None` because `x` doesn't have `requires_grad` set to `True`.\n",
        "\n",
        "The \"grad\" in `w.grad` is short for _gradient_, which is another term for derivative. The term _gradient_ is primarily used while dealing with vectors and matrices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvR-LWzgkfM8"
      },
      "source": [
        "## Tensor functions\n",
        "\n",
        "Apart from arithmetic operations, the `torch` module also contains many functions for creating and manipulating tensors. Let's look at some examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi5eISBckfM8",
        "outputId": "0de33509-4984-4d8f-c272-151695a9802f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Create a tensor with a fixed value for every element\n",
        "t6 = torch.full((3, 2), 42)\n",
        "t6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caAPy-P7kfM8",
        "outputId": "679f1831-29ba-4dd0-c1e2-75f11b9fd0de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Concatenate two tensors with compatible shapes\n",
        "t7 = torch.cat((t3, t6))\n",
        "t7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHmUkGOHkfM9",
        "outputId": "a21521d5-e61a-40d7-ca4c-9a41f18e473e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Compute the sin of each element\n",
        "t8 = torch.sin(t7)\n",
        "t8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UFIgc-kfM9",
        "outputId": "ba505d7d-7c32-41fc-a7f5-8cb4b92ddf26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Change the shape of a tensor\n",
        "t9 = t8.reshape(3, 2, 2)\n",
        "t9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YK9aNsnkfM9"
      },
      "source": [
        "You can learn more about tensor operations here: https://pytorch.org/docs/stable/torch.html . Experiment with some more tensor functions and operations using the empty cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTgXrNyRkfM-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36942dZpkfM-"
      },
      "source": [
        "## Interoperability with Numpy\n",
        "\n",
        "[Numpy](http://www.numpy.org/) is a popular open-source library used for mathematical and scientific computing in Python. It enables efficient operations on large multi-dimensional arrays and has a vast ecosystem of supporting libraries, including:\n",
        "\n",
        "* [Pandas](https://pandas.pydata.org/) for file I/O and data analysis\n",
        "* [Matplotlib](https://matplotlib.org/) for plotting and visualization\n",
        "* [OpenCV](https://opencv.org/) for image and video processing\n",
        "\n",
        "\n",
        "Instead of reinventing the wheel, PyTorch interoperates well with Numpy to leverage its existing ecosystem of tools and libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKH8QMxDkfM-"
      },
      "source": [
        "Here's how we create an array in Numpy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlCWcXUckfM_",
        "outputId": "ef6e6ad3-3fea-4e78-e5b3-d6c09cb58e7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1, 2], [3, 4.]])\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V-UeD40kfM_"
      },
      "source": [
        "We can convert a Numpy array to a PyTorch tensor using `torch.from_numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaPUjIiokfNB",
        "outputId": "c8ad3bb6-f60c-4af1-c7ef-035a52244434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-kN6vp4kfNC"
      },
      "source": [
        "Let's verify that the numpy array and torch tensor have similar data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KL76Ma8ekfND",
        "outputId": "54ab5324-e79b-407b-b8c0-89ef879617df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x.dtype, y.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-vuHKXXkfNE"
      },
      "source": [
        "We can convert a PyTorch tensor to a Numpy array using the `.numpy` method of a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEBugCySkfNE",
        "outputId": "fb7b7496-d808-4d6f-8145-403652938ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Convert a torch tensor to a numpy array\n",
        "z = y.numpy()\n",
        "z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgxySGeWkfNE"
      },
      "source": [
        "The interoperability between PyTorch and Numpy is essential because most datasets you'll work with will likely be read and preprocessed as Numpy arrays.\n",
        "\n",
        "You might wonder why we need a library like PyTorch at all since Numpy already provides data structures and utilities for working with multi-dimensional numeric data. There are two main reasons:\n",
        "\n",
        "1. **Autograd**: The ability to automatically compute gradients for tensor operations is essential for training deep learning models.\n",
        "2. **GPU support**: While working with massive datasets and large models, PyTorch tensor operations can be performed efficiently using a Graphics Processing Unit (GPU). Computations that might typically take hours can be completed within minutes using GPUs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOg5UDH45k9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear-regression from scrach using pytorch"
      ],
      "metadata": {
        "id": "GPb963Lz5laq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "elamAaJH5tYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making training data\n",
        "# Input (temp, rainfall, humidity)\n",
        "inputs = np.array([[73, 67, 43],\n",
        "                   [91, 88, 64],\n",
        "                   [87, 134, 58],\n",
        "                   [102, 43, 37],\n",
        "                   [69, 96, 70]], dtype='float32')"
      ],
      "metadata": {
        "id": "Ze7LRltk5tUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Targets (apples, oranges)\n",
        "target = np.array([[56, 70],\n",
        "                    [81, 101],\n",
        "                    [119, 133],\n",
        "                    [22, 37],\n",
        "                    [103, 119]], dtype='float32')"
      ],
      "metadata": {
        "id": "ars5xesW5tRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert input and target to tensors\n",
        "inputs = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(target)\n",
        "\n",
        "print(inputs,\"\\n\")\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92TqO635tPO",
        "outputId": "89e342c8-3939-4f44-8b67-6da057bfc0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]]) \n",
            "\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# weights and biases\n",
        "w = torch.randn(2,3 , requires_grad=True)\n",
        "b = torch.randn(2, requires_grad=True)\n",
        "\n",
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m_2iaph5tMh",
        "outputId": "9cef4156-01f7-4b8c-d157-cb8247a9b63d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9360, -3.2651,  0.1739],\n",
            "        [ 0.8647, -1.0314, -0.5762]], requires_grad=True)\n",
            "tensor([ 0.4978, -0.2630], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#define the model\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() + b"
      ],
      "metadata": {
        "id": "ZHqEIQKU56cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9J__d3l56Ze",
        "outputId": "eedb0f57-552b-4edf-948b-f349f8cff3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-279.1155,  -31.0234],\n",
            "        [-360.8790,  -49.2193],\n",
            "        [-508.3732,  -96.6649],\n",
            "        [-228.9407,   22.2628],\n",
            "        [-365.3642,  -79.9504]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#actual\n",
        "print(target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV0XrG2k56Xf",
        "outputId": "b5b59959-16a2-40ca-8ac9-b1c201d3c221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 133.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function MSE\n",
        "def MSE(actual, target):\n",
        "  diff = actual - target\n",
        "  return torch.sum(diff * diff) / diff.numel()"
      ],
      "metadata": {
        "id": "vlr1NKsC56Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQJRKGXP56RJ",
        "outputId": "33cfbbd2-6a17-4145-d1da-1d716d48aa08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(110880.8750, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compute gradients\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "iGypGOsF56Oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w, \"\\n\")\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKRT4IVP56Lu",
        "outputId": "283af31e-52dd-41e5-aec1-02336df2a05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9360, -3.2651,  0.1739],\n",
            "        [ 0.8647, -1.0314, -0.5762]], requires_grad=True) \n",
            "\n",
            "tensor([[-35433.7969, -40231.9023, -24229.6328],\n",
            "        [-11251.2559, -14099.1797,  -8350.0820]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWMcsxjz6IBr",
        "outputId": "ba053027-5420-41f5-a75c-04b740ca68bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4978, -0.2630], requires_grad=True) \n",
            "\n",
            "tensor([-424.7345, -138.9190])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reset grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjdeYBsU6H-6",
        "outputId": "5832a926-e98c-4f5e-9e17-ad785eb8e0d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust params\n",
        "\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIbBPr-x6H8l",
        "outputId": "f8974e80-681f-420e-8b9e-fcfe995ebedf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-279.1155,  -31.0234],\n",
            "        [-360.8790,  -49.2193],\n",
            "        [-508.3732,  -96.6649],\n",
            "        [-228.9407,   22.2628],\n",
            "        [-365.3642,  -79.9504]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEOGA0cy6PzN",
        "outputId": "8635d910-3448-46ff-e47d-4a5154c0abab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(110880.8750, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad, \"\\n\")\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du5TIt2e6Pwg",
        "outputId": "9704e23a-f37a-4137-a71e-37f673dca82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-35433.7969, -40231.9023, -24229.6328],\n",
            "        [-11251.2559, -14099.1797,  -8350.0820]]) \n",
            "\n",
            "tensor([-424.7345, -138.9190])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # adjust weight & reset grad\n",
        "with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ],
      "metadata": {
        "id": "Jx0SBLV56PtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD2CAdtn6Pq2",
        "outputId": "0568d999-f00f-4567-9c22-e71d7775fdf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5817, -2.8628,  0.4162],\n",
            "        [ 0.9772, -0.8904, -0.4927]], requires_grad=True)\n",
            "tensor([ 0.5020, -0.2616], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate again\n",
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZT-GtGY6Xzq",
        "outputId": "e8246072-6438-42e2-fae8-119c729052ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(75765.4062, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for multiple epochs\n",
        "for i in range(400):\n",
        "  preds = model(inputs)\n",
        "  loss = MSE(target, preds)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "     w -= w.grad * 1e-5 # learning rate\n",
        "     b -= b.grad * 1e-5\n",
        "     w.grad.zero_()\n",
        "     b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{100}) & Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijRMFN3C6Xv1",
        "outputId": "dfe54b14-a643-4646-8046-c2147aea9e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/100) & Loss 75765.40625\n",
            "Epochs(1/100) & Loss 52088.75\n",
            "Epochs(2/100) & Loss 36120.72265625\n",
            "Epochs(3/100) & Loss 25347.583984375\n",
            "Epochs(4/100) & Loss 18075.365234375\n",
            "Epochs(5/100) & Loss 13162.5283203125\n",
            "Epochs(6/100) & Loss 9839.7890625\n",
            "Epochs(7/100) & Loss 7588.75\n",
            "Epochs(8/100) & Loss 6060.0634765625\n",
            "Epochs(9/100) & Loss 5018.30615234375\n",
            "Epochs(10/100) & Loss 4304.82958984375\n",
            "Epochs(11/100) & Loss 3812.721435546875\n",
            "Epochs(12/100) & Loss 3469.931640625\n",
            "Epochs(13/100) & Loss 3227.90576171875\n",
            "Epochs(14/100) & Loss 3053.92236328125\n",
            "Epochs(15/100) & Loss 2925.927734375\n",
            "Epochs(16/100) & Loss 2829.060302734375\n",
            "Epochs(17/100) & Loss 2753.3017578125\n",
            "Epochs(18/100) & Loss 2691.900146484375\n",
            "Epochs(19/100) & Loss 2640.30419921875\n",
            "Epochs(20/100) & Loss 2595.443359375\n",
            "Epochs(21/100) & Loss 2555.24853515625\n",
            "Epochs(22/100) & Loss 2518.322998046875\n",
            "Epochs(23/100) & Loss 2483.724853515625\n",
            "Epochs(24/100) & Loss 2450.81640625\n",
            "Epochs(25/100) & Loss 2419.167236328125\n",
            "Epochs(26/100) & Loss 2388.48583984375\n",
            "Epochs(27/100) & Loss 2358.57470703125\n",
            "Epochs(28/100) & Loss 2329.297607421875\n",
            "Epochs(29/100) & Loss 2300.56298828125\n",
            "Epochs(30/100) & Loss 2272.30615234375\n",
            "Epochs(31/100) & Loss 2244.484375\n",
            "Epochs(32/100) & Loss 2217.064453125\n",
            "Epochs(33/100) & Loss 2190.025390625\n",
            "Epochs(34/100) & Loss 2163.35009765625\n",
            "Epochs(35/100) & Loss 2137.02587890625\n",
            "Epochs(36/100) & Loss 2111.04345703125\n",
            "Epochs(37/100) & Loss 2085.39501953125\n",
            "Epochs(38/100) & Loss 2060.07275390625\n",
            "Epochs(39/100) & Loss 2035.0718994140625\n",
            "Epochs(40/100) & Loss 2010.387451171875\n",
            "Epochs(41/100) & Loss 1986.0140380859375\n",
            "Epochs(42/100) & Loss 1961.9476318359375\n",
            "Epochs(43/100) & Loss 1938.18359375\n",
            "Epochs(44/100) & Loss 1914.71875\n",
            "Epochs(45/100) & Loss 1891.548583984375\n",
            "Epochs(46/100) & Loss 1868.669189453125\n",
            "Epochs(47/100) & Loss 1846.076904296875\n",
            "Epochs(48/100) & Loss 1823.7685546875\n",
            "Epochs(49/100) & Loss 1801.739501953125\n",
            "Epochs(50/100) & Loss 1779.987548828125\n",
            "Epochs(51/100) & Loss 1758.507568359375\n",
            "Epochs(52/100) & Loss 1737.297607421875\n",
            "Epochs(53/100) & Loss 1716.3531494140625\n",
            "Epochs(54/100) & Loss 1695.671630859375\n",
            "Epochs(55/100) & Loss 1675.2496337890625\n",
            "Epochs(56/100) & Loss 1655.0836181640625\n",
            "Epochs(57/100) & Loss 1635.1702880859375\n",
            "Epochs(58/100) & Loss 1615.506591796875\n",
            "Epochs(59/100) & Loss 1596.0894775390625\n",
            "Epochs(60/100) & Loss 1576.9154052734375\n",
            "Epochs(61/100) & Loss 1557.982177734375\n",
            "Epochs(62/100) & Loss 1539.2857666015625\n",
            "Epochs(63/100) & Loss 1520.8238525390625\n",
            "Epochs(64/100) & Loss 1502.5931396484375\n",
            "Epochs(65/100) & Loss 1484.5909423828125\n",
            "Epochs(66/100) & Loss 1466.8143310546875\n",
            "Epochs(67/100) & Loss 1449.2601318359375\n",
            "Epochs(68/100) & Loss 1431.926025390625\n",
            "Epochs(69/100) & Loss 1414.8089599609375\n",
            "Epochs(70/100) & Loss 1397.906494140625\n",
            "Epochs(71/100) & Loss 1381.2152099609375\n",
            "Epochs(72/100) & Loss 1364.733154296875\n",
            "Epochs(73/100) & Loss 1348.4573974609375\n",
            "Epochs(74/100) & Loss 1332.385498046875\n",
            "Epochs(75/100) & Loss 1316.5146484375\n",
            "Epochs(76/100) & Loss 1300.8424072265625\n",
            "Epochs(77/100) & Loss 1285.366455078125\n",
            "Epochs(78/100) & Loss 1270.083984375\n",
            "Epochs(79/100) & Loss 1254.992919921875\n",
            "Epochs(80/100) & Loss 1240.090576171875\n",
            "Epochs(81/100) & Loss 1225.374755859375\n",
            "Epochs(82/100) & Loss 1210.8428955078125\n",
            "Epochs(83/100) & Loss 1196.492919921875\n",
            "Epochs(84/100) & Loss 1182.322265625\n",
            "Epochs(85/100) & Loss 1168.328857421875\n",
            "Epochs(86/100) & Loss 1154.510498046875\n",
            "Epochs(87/100) & Loss 1140.86474609375\n",
            "Epochs(88/100) & Loss 1127.3897705078125\n",
            "Epochs(89/100) & Loss 1114.0830078125\n",
            "Epochs(90/100) & Loss 1100.942626953125\n",
            "Epochs(91/100) & Loss 1087.966552734375\n",
            "Epochs(92/100) & Loss 1075.1524658203125\n",
            "Epochs(93/100) & Loss 1062.4984130859375\n",
            "Epochs(94/100) & Loss 1050.0025634765625\n",
            "Epochs(95/100) & Loss 1037.662841796875\n",
            "Epochs(96/100) & Loss 1025.477294921875\n",
            "Epochs(97/100) & Loss 1013.4439697265625\n",
            "Epochs(98/100) & Loss 1001.5606689453125\n",
            "Epochs(99/100) & Loss 989.8259887695312\n",
            "Epochs(100/100) & Loss 978.2376098632812\n",
            "Epochs(101/100) & Loss 966.7937622070312\n",
            "Epochs(102/100) & Loss 955.4929809570312\n",
            "Epochs(103/100) & Loss 944.3331909179688\n",
            "Epochs(104/100) & Loss 933.3126220703125\n",
            "Epochs(105/100) & Loss 922.4293212890625\n",
            "Epochs(106/100) & Loss 911.6820068359375\n",
            "Epochs(107/100) & Loss 901.0687255859375\n",
            "Epochs(108/100) & Loss 890.5877075195312\n",
            "Epochs(109/100) & Loss 880.2374877929688\n",
            "Epochs(110/100) & Loss 870.0162353515625\n",
            "Epochs(111/100) & Loss 859.9222412109375\n",
            "Epochs(112/100) & Loss 849.9542846679688\n",
            "Epochs(113/100) & Loss 840.1105346679688\n",
            "Epochs(114/100) & Loss 830.3895263671875\n",
            "Epochs(115/100) & Loss 820.7892456054688\n",
            "Epochs(116/100) & Loss 811.3089599609375\n",
            "Epochs(117/100) & Loss 801.9466552734375\n",
            "Epochs(118/100) & Loss 792.7008056640625\n",
            "Epochs(119/100) & Loss 783.5700073242188\n",
            "Epochs(120/100) & Loss 774.5531616210938\n",
            "Epochs(121/100) & Loss 765.6484375\n",
            "Epochs(122/100) & Loss 756.8543090820312\n",
            "Epochs(123/100) & Loss 748.169921875\n",
            "Epochs(124/100) & Loss 739.5933837890625\n",
            "Epochs(125/100) & Loss 731.1236572265625\n",
            "Epochs(126/100) & Loss 722.7591552734375\n",
            "Epochs(127/100) & Loss 714.4987182617188\n",
            "Epochs(128/100) & Loss 706.3410034179688\n",
            "Epochs(129/100) & Loss 698.2847900390625\n",
            "Epochs(130/100) & Loss 690.32861328125\n",
            "Epochs(131/100) & Loss 682.4713134765625\n",
            "Epochs(132/100) & Loss 674.7117919921875\n",
            "Epochs(133/100) & Loss 667.0484619140625\n",
            "Epochs(134/100) & Loss 659.4802856445312\n",
            "Epochs(135/100) & Loss 652.0061645507812\n",
            "Epochs(136/100) & Loss 644.6248779296875\n",
            "Epochs(137/100) & Loss 637.3352661132812\n",
            "Epochs(138/100) & Loss 630.1359252929688\n",
            "Epochs(139/100) & Loss 623.0261840820312\n",
            "Epochs(140/100) & Loss 616.0045166015625\n",
            "Epochs(141/100) & Loss 609.06982421875\n",
            "Epochs(142/100) & Loss 602.2213134765625\n",
            "Epochs(143/100) & Loss 595.4576416015625\n",
            "Epochs(144/100) & Loss 588.7779541015625\n",
            "Epochs(145/100) & Loss 582.180908203125\n",
            "Epochs(146/100) & Loss 575.6657104492188\n",
            "Epochs(147/100) & Loss 569.2310791015625\n",
            "Epochs(148/100) & Loss 562.8763427734375\n",
            "Epochs(149/100) & Loss 556.6002197265625\n",
            "Epochs(150/100) & Loss 550.40185546875\n",
            "Epochs(151/100) & Loss 544.2801513671875\n",
            "Epochs(152/100) & Loss 538.2343139648438\n",
            "Epochs(153/100) & Loss 532.2632446289062\n",
            "Epochs(154/100) & Loss 526.3660888671875\n",
            "Epochs(155/100) & Loss 520.5418090820312\n",
            "Epochs(156/100) & Loss 514.7894897460938\n",
            "Epochs(157/100) & Loss 509.1084899902344\n",
            "Epochs(158/100) & Loss 503.49749755859375\n",
            "Epochs(159/100) & Loss 497.9559631347656\n",
            "Epochs(160/100) & Loss 492.48291015625\n",
            "Epochs(161/100) & Loss 487.077392578125\n",
            "Epochs(162/100) & Loss 481.7386779785156\n",
            "Epochs(163/100) & Loss 476.4658203125\n",
            "Epochs(164/100) & Loss 471.25811767578125\n",
            "Epochs(165/100) & Loss 466.1146545410156\n",
            "Epochs(166/100) & Loss 461.0345764160156\n",
            "Epochs(167/100) & Loss 456.01727294921875\n",
            "Epochs(168/100) & Loss 451.0616760253906\n",
            "Epochs(169/100) & Loss 446.1673889160156\n",
            "Epochs(170/100) & Loss 441.33331298828125\n",
            "Epochs(171/100) & Loss 436.5586853027344\n",
            "Epochs(172/100) & Loss 431.8429260253906\n",
            "Epochs(173/100) & Loss 427.185302734375\n",
            "Epochs(174/100) & Loss 422.5850524902344\n",
            "Epochs(175/100) & Loss 418.0413513183594\n",
            "Epochs(176/100) & Loss 413.5536193847656\n",
            "Epochs(177/100) & Loss 409.12103271484375\n",
            "Epochs(178/100) & Loss 404.74298095703125\n",
            "Epochs(179/100) & Loss 400.41876220703125\n",
            "Epochs(180/100) & Loss 396.14776611328125\n",
            "Epochs(181/100) & Loss 391.9290466308594\n",
            "Epochs(182/100) & Loss 387.7622985839844\n",
            "Epochs(183/100) & Loss 383.6466064453125\n",
            "Epochs(184/100) & Loss 379.5816345214844\n",
            "Epochs(185/100) & Loss 375.56640625\n",
            "Epochs(186/100) & Loss 371.6004943847656\n",
            "Epochs(187/100) & Loss 367.6831970214844\n",
            "Epochs(188/100) & Loss 363.8139343261719\n",
            "Epochs(189/100) & Loss 359.9920959472656\n",
            "Epochs(190/100) & Loss 356.21710205078125\n",
            "Epochs(191/100) & Loss 352.4883728027344\n",
            "Epochs(192/100) & Loss 348.8052978515625\n",
            "Epochs(193/100) & Loss 345.167236328125\n",
            "Epochs(194/100) & Loss 341.5737609863281\n",
            "Epochs(195/100) & Loss 338.0242614746094\n",
            "Epochs(196/100) & Loss 334.51812744140625\n",
            "Epochs(197/100) & Loss 331.054931640625\n",
            "Epochs(198/100) & Loss 327.63397216796875\n",
            "Epochs(199/100) & Loss 324.2547302246094\n",
            "Epochs(200/100) & Loss 320.91693115234375\n",
            "Epochs(201/100) & Loss 317.6197814941406\n",
            "Epochs(202/100) & Loss 314.36285400390625\n",
            "Epochs(203/100) & Loss 311.1457214355469\n",
            "Epochs(204/100) & Loss 307.96783447265625\n",
            "Epochs(205/100) & Loss 304.82867431640625\n",
            "Epochs(206/100) & Loss 301.727783203125\n",
            "Epochs(207/100) & Loss 298.6646423339844\n",
            "Epochs(208/100) & Loss 295.6387634277344\n",
            "Epochs(209/100) & Loss 292.6497802734375\n",
            "Epochs(210/100) & Loss 289.6971130371094\n",
            "Epochs(211/100) & Loss 286.78033447265625\n",
            "Epochs(212/100) & Loss 283.89910888671875\n",
            "Epochs(213/100) & Loss 281.05279541015625\n",
            "Epochs(214/100) & Loss 278.24114990234375\n",
            "Epochs(215/100) & Loss 275.4635314941406\n",
            "Epochs(216/100) & Loss 272.71978759765625\n",
            "Epochs(217/100) & Loss 270.0091857910156\n",
            "Epochs(218/100) & Loss 267.33148193359375\n",
            "Epochs(219/100) & Loss 264.6863098144531\n",
            "Epochs(220/100) & Loss 262.0731506347656\n",
            "Epochs(221/100) & Loss 259.4916076660156\n",
            "Epochs(222/100) & Loss 256.94134521484375\n",
            "Epochs(223/100) & Loss 254.4219207763672\n",
            "Epochs(224/100) & Loss 251.9329833984375\n",
            "Epochs(225/100) & Loss 249.47409057617188\n",
            "Epochs(226/100) & Loss 247.04501342773438\n",
            "Epochs(227/100) & Loss 244.645263671875\n",
            "Epochs(228/100) & Loss 242.27444458007812\n",
            "Epochs(229/100) & Loss 239.9322509765625\n",
            "Epochs(230/100) & Loss 237.6182861328125\n",
            "Epochs(231/100) & Loss 235.3321533203125\n",
            "Epochs(232/100) & Loss 233.07369995117188\n",
            "Epochs(233/100) & Loss 230.8423614501953\n",
            "Epochs(234/100) & Loss 228.63790893554688\n",
            "Epochs(235/100) & Loss 226.4600372314453\n",
            "Epochs(236/100) & Loss 224.30819702148438\n",
            "Epochs(237/100) & Loss 222.18240356445312\n",
            "Epochs(238/100) & Loss 220.08203125\n",
            "Epochs(239/100) & Loss 218.0068359375\n",
            "Epochs(240/100) & Loss 215.95669555664062\n",
            "Epochs(241/100) & Loss 213.93099975585938\n",
            "Epochs(242/100) & Loss 211.9296417236328\n",
            "Epochs(243/100) & Loss 209.9523468017578\n",
            "Epochs(244/100) & Loss 207.9987030029297\n",
            "Epochs(245/100) & Loss 206.06832885742188\n",
            "Epochs(246/100) & Loss 204.1610870361328\n",
            "Epochs(247/100) & Loss 202.27671813964844\n",
            "Epochs(248/100) & Loss 200.41476440429688\n",
            "Epochs(249/100) & Loss 198.57504272460938\n",
            "Epochs(250/100) & Loss 196.75735473632812\n",
            "Epochs(251/100) & Loss 194.96133422851562\n",
            "Epochs(252/100) & Loss 193.18667602539062\n",
            "Epochs(253/100) & Loss 191.4331817626953\n",
            "Epochs(254/100) & Loss 189.70053100585938\n",
            "Epochs(255/100) & Loss 187.9885711669922\n",
            "Epochs(256/100) & Loss 186.29684448242188\n",
            "Epochs(257/100) & Loss 184.6253204345703\n",
            "Epochs(258/100) & Loss 182.97361755371094\n",
            "Epochs(259/100) & Loss 181.3415069580078\n",
            "Epochs(260/100) & Loss 179.728759765625\n",
            "Epochs(261/100) & Loss 178.1351318359375\n",
            "Epochs(262/100) & Loss 176.56033325195312\n",
            "Epochs(263/100) & Loss 175.0042266845703\n",
            "Epochs(264/100) & Loss 173.46646118164062\n",
            "Epochs(265/100) & Loss 171.94699096679688\n",
            "Epochs(266/100) & Loss 170.4453582763672\n",
            "Epochs(267/100) & Loss 168.96144104003906\n",
            "Epochs(268/100) & Loss 167.4951171875\n",
            "Epochs(269/100) & Loss 166.04598999023438\n",
            "Epochs(270/100) & Loss 164.61404418945312\n",
            "Epochs(271/100) & Loss 163.19882202148438\n",
            "Epochs(272/100) & Loss 161.80030822753906\n",
            "Epochs(273/100) & Loss 160.41824340820312\n",
            "Epochs(274/100) & Loss 159.0523681640625\n",
            "Epochs(275/100) & Loss 157.7025604248047\n",
            "Epochs(276/100) & Loss 156.3686065673828\n",
            "Epochs(277/100) & Loss 155.05020141601562\n",
            "Epochs(278/100) & Loss 153.74722290039062\n",
            "Epochs(279/100) & Loss 152.4595947265625\n",
            "Epochs(280/100) & Loss 151.18695068359375\n",
            "Epochs(281/100) & Loss 149.92918395996094\n",
            "Epochs(282/100) & Loss 148.68612670898438\n",
            "Epochs(283/100) & Loss 147.45748901367188\n",
            "Epochs(284/100) & Loss 146.24325561523438\n",
            "Epochs(285/100) & Loss 145.04306030273438\n",
            "Epochs(286/100) & Loss 143.85690307617188\n",
            "Epochs(287/100) & Loss 142.6845245361328\n",
            "Epochs(288/100) & Loss 141.52572631835938\n",
            "Epochs(289/100) & Loss 140.38037109375\n",
            "Epochs(290/100) & Loss 139.24835205078125\n",
            "Epochs(291/100) & Loss 138.1294403076172\n",
            "Epochs(292/100) & Loss 137.0233917236328\n",
            "Epochs(293/100) & Loss 135.93019104003906\n",
            "Epochs(294/100) & Loss 134.849609375\n",
            "Epochs(295/100) & Loss 133.78152465820312\n",
            "Epochs(296/100) & Loss 132.72569274902344\n",
            "Epochs(297/100) & Loss 131.6820831298828\n",
            "Epochs(298/100) & Loss 130.65045166015625\n",
            "Epochs(299/100) & Loss 129.63070678710938\n",
            "Epochs(300/100) & Loss 128.62261962890625\n",
            "Epochs(301/100) & Loss 127.62614440917969\n",
            "Epochs(302/100) & Loss 126.64106750488281\n",
            "Epochs(303/100) & Loss 125.66734313964844\n",
            "Epochs(304/100) & Loss 124.70469665527344\n",
            "Epochs(305/100) & Loss 123.7530517578125\n",
            "Epochs(306/100) & Loss 122.8122787475586\n",
            "Epochs(307/100) & Loss 121.88226318359375\n",
            "Epochs(308/100) & Loss 120.96281433105469\n",
            "Epochs(309/100) & Loss 120.0538330078125\n",
            "Epochs(310/100) & Loss 119.1552734375\n",
            "Epochs(311/100) & Loss 118.2667465209961\n",
            "Epochs(312/100) & Loss 117.38846588134766\n",
            "Epochs(313/100) & Loss 116.52009582519531\n",
            "Epochs(314/100) & Loss 115.66153717041016\n",
            "Epochs(315/100) & Loss 114.81266784667969\n",
            "Epochs(316/100) & Loss 113.97335052490234\n",
            "Epochs(317/100) & Loss 113.14361572265625\n",
            "Epochs(318/100) & Loss 112.32319641113281\n",
            "Epochs(319/100) & Loss 111.51203918457031\n",
            "Epochs(320/100) & Loss 110.70989990234375\n",
            "Epochs(321/100) & Loss 109.9168701171875\n",
            "Epochs(322/100) & Loss 109.1327133178711\n",
            "Epochs(323/100) & Loss 108.3573226928711\n",
            "Epochs(324/100) & Loss 107.59063720703125\n",
            "Epochs(325/100) & Loss 106.83248138427734\n",
            "Epochs(326/100) & Loss 106.08284759521484\n",
            "Epochs(327/100) & Loss 105.34153747558594\n",
            "Epochs(328/100) & Loss 104.60848236083984\n",
            "Epochs(329/100) & Loss 103.88360595703125\n",
            "Epochs(330/100) & Loss 103.16676330566406\n",
            "Epochs(331/100) & Loss 102.4578857421875\n",
            "Epochs(332/100) & Loss 101.75688171386719\n",
            "Epochs(333/100) & Loss 101.0635757446289\n",
            "Epochs(334/100) & Loss 100.37793731689453\n",
            "Epochs(335/100) & Loss 99.6999282836914\n",
            "Epochs(336/100) & Loss 99.0293960571289\n",
            "Epochs(337/100) & Loss 98.36617279052734\n",
            "Epochs(338/100) & Loss 97.7103042602539\n",
            "Epochs(339/100) & Loss 97.06159210205078\n",
            "Epochs(340/100) & Loss 96.42002868652344\n",
            "Epochs(341/100) & Loss 95.7854232788086\n",
            "Epochs(342/100) & Loss 95.15788269042969\n",
            "Epochs(343/100) & Loss 94.53712463378906\n",
            "Epochs(344/100) & Loss 93.92306518554688\n",
            "Epochs(345/100) & Loss 93.31578063964844\n",
            "Epochs(346/100) & Loss 92.71503448486328\n",
            "Epochs(347/100) & Loss 92.12081146240234\n",
            "Epochs(348/100) & Loss 91.53311920166016\n",
            "Epochs(349/100) & Loss 90.95165252685547\n",
            "Epochs(350/100) & Loss 90.37657165527344\n",
            "Epochs(351/100) & Loss 89.80763244628906\n",
            "Epochs(352/100) & Loss 89.244873046875\n",
            "Epochs(353/100) & Loss 88.6881103515625\n",
            "Epochs(354/100) & Loss 88.13738250732422\n",
            "Epochs(355/100) & Loss 87.5925521850586\n",
            "Epochs(356/100) & Loss 87.0535659790039\n",
            "Epochs(357/100) & Loss 86.52027893066406\n",
            "Epochs(358/100) & Loss 85.99272918701172\n",
            "Epochs(359/100) & Loss 85.47074127197266\n",
            "Epochs(360/100) & Loss 84.95435333251953\n",
            "Epochs(361/100) & Loss 84.44343566894531\n",
            "Epochs(362/100) & Loss 83.93795013427734\n",
            "Epochs(363/100) & Loss 83.43780517578125\n",
            "Epochs(364/100) & Loss 82.94291687011719\n",
            "Epochs(365/100) & Loss 82.45328521728516\n",
            "Epochs(366/100) & Loss 81.96879577636719\n",
            "Epochs(367/100) & Loss 81.48942565917969\n",
            "Epochs(368/100) & Loss 81.0150375366211\n",
            "Epochs(369/100) & Loss 80.54563903808594\n",
            "Epochs(370/100) & Loss 80.08116149902344\n",
            "Epochs(371/100) & Loss 79.62149810791016\n",
            "Epochs(372/100) & Loss 79.16664123535156\n",
            "Epochs(373/100) & Loss 78.7164535522461\n",
            "Epochs(374/100) & Loss 78.27107238769531\n",
            "Epochs(375/100) & Loss 77.8301773071289\n",
            "Epochs(376/100) & Loss 77.39387512207031\n",
            "Epochs(377/100) & Loss 76.96209716796875\n",
            "Epochs(378/100) & Loss 76.53474426269531\n",
            "Epochs(379/100) & Loss 76.11177062988281\n",
            "Epochs(380/100) & Loss 75.69317626953125\n",
            "Epochs(381/100) & Loss 75.27879333496094\n",
            "Epochs(382/100) & Loss 74.86875915527344\n",
            "Epochs(383/100) & Loss 74.46283721923828\n",
            "Epochs(384/100) & Loss 74.06108093261719\n",
            "Epochs(385/100) & Loss 73.663330078125\n",
            "Epochs(386/100) & Loss 73.26969146728516\n",
            "Epochs(387/100) & Loss 72.88002014160156\n",
            "Epochs(388/100) & Loss 72.49427795410156\n",
            "Epochs(389/100) & Loss 72.11234283447266\n",
            "Epochs(390/100) & Loss 71.7343521118164\n",
            "Epochs(391/100) & Loss 71.36018371582031\n",
            "Epochs(392/100) & Loss 70.9896469116211\n",
            "Epochs(393/100) & Loss 70.62281799316406\n",
            "Epochs(394/100) & Loss 70.25973510742188\n",
            "Epochs(395/100) & Loss 69.90019226074219\n",
            "Epochs(396/100) & Loss 69.54423522949219\n",
            "Epochs(397/100) & Loss 69.1917724609375\n",
            "Epochs(398/100) & Loss 68.84284973144531\n",
            "Epochs(399/100) & Loss 68.4973373413086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rShT9Hmj6XtR",
        "outputId": "3a164ba1-0781-4951-fab8-71d084c1ba62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(68.1553, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cezq8zGu6Xqs",
        "outputId": "a4ef29e0-7465-4f20-cd21-ebe617907f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.255619331662308"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvsKGPfB6XoH",
        "outputId": "31277d35-68f3-4cbe-e73a-74236e68641f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.0557,  72.1434],\n",
              "        [ 88.5395,  97.2732],\n",
              "        [102.8608, 137.7344],\n",
              "        [ 26.3404,  47.4669],\n",
              "        [109.9683, 107.0769]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U8284MJ6p5w",
        "outputId": "53914aca-0249-46b1-a9a7-745fba07c1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 133.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## You can see they are almost close earch other"
      ],
      "metadata": {
        "id": "3jkj32ag6p3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHrHiAXZ6pzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network using Pytorch"
      ],
      "metadata": {
        "id": "6-OUXNOx3CPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHo8uHimkfNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f417eca2-1271-4725-d16c-b06daef05340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed May 24 08:25:17 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# To check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "jv4zRj3u3LtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swc3R2Ki3OSI",
        "outputId": "084bc77d-4b4c-40ce-c74a-f139ec81d50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 26421880/26421880 [00:01<00:00, 15982108.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 29515/29515 [00:00<00:00, 271635.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 4422102/4422102 [00:00<00:00, 5083357.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 5148/5148 [00:00<00:00, 6987791.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd71u_LZ3QMo",
        "outputId": "cadc622c-044e-4923-bc18-1e2b6e0c9ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    # print(X)\n",
        "    # print(y)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z8xEoct3Taa",
        "outputId": "e5774145-9510-40d5-8322-7b24d74aab77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fx_2V-C83aUS",
        "outputId": "e0fde571-427a-4998-f6db-72467f034eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueZJS_-L3VQ4",
        "outputId": "92675220-831c-40b1-aed1-44c1c7503842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "1SEEk4fz3ey2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "tryz3wtG3ewp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "Z1C_N3if3j-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UxIUc-Y3mSp",
        "outputId": "1803e0d5-a1d4-47a5-abe7-9328599609da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.316672  [    0/60000]\n",
            "loss: 2.299611  [ 6400/60000]\n",
            "loss: 2.276056  [12800/60000]\n",
            "loss: 2.267389  [19200/60000]\n",
            "loss: 2.250305  [25600/60000]\n",
            "loss: 2.210238  [32000/60000]\n",
            "loss: 2.231450  [38400/60000]\n",
            "loss: 2.190959  [44800/60000]\n",
            "loss: 2.200532  [51200/60000]\n",
            "loss: 2.153820  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 36.2%, Avg loss: 2.147636 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.171121  [    0/60000]\n",
            "loss: 2.154280  [ 6400/60000]\n",
            "loss: 2.090852  [12800/60000]\n",
            "loss: 2.105507  [19200/60000]\n",
            "loss: 2.051154  [25600/60000]\n",
            "loss: 1.985906  [32000/60000]\n",
            "loss: 2.021355  [38400/60000]\n",
            "loss: 1.935196  [44800/60000]\n",
            "loss: 1.952712  [51200/60000]\n",
            "loss: 1.864827  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 51.2%, Avg loss: 1.863941 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.910603  [    0/60000]\n",
            "loss: 1.873535  [ 6400/60000]\n",
            "loss: 1.752214  [12800/60000]\n",
            "loss: 1.789106  [19200/60000]\n",
            "loss: 1.676216  [25600/60000]\n",
            "loss: 1.630203  [32000/60000]\n",
            "loss: 1.652746  [38400/60000]\n",
            "loss: 1.553478  [44800/60000]\n",
            "loss: 1.586449  [51200/60000]\n",
            "loss: 1.473644  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.0%, Avg loss: 1.494110 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.571199  [    0/60000]\n",
            "loss: 1.534655  [ 6400/60000]\n",
            "loss: 1.384191  [12800/60000]\n",
            "loss: 1.451482  [19200/60000]\n",
            "loss: 1.334421  [25600/60000]\n",
            "loss: 1.332630  [32000/60000]\n",
            "loss: 1.344593  [38400/60000]\n",
            "loss: 1.269534  [44800/60000]\n",
            "loss: 1.310125  [51200/60000]\n",
            "loss: 1.211971  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.5%, Avg loss: 1.237874 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.320967  [    0/60000]\n",
            "loss: 1.302911  [ 6400/60000]\n",
            "loss: 1.136904  [12800/60000]\n",
            "loss: 1.240004  [19200/60000]\n",
            "loss: 1.119631  [25600/60000]\n",
            "loss: 1.143259  [32000/60000]\n",
            "loss: 1.161697  [38400/60000]\n",
            "loss: 1.096488  [44800/60000]\n",
            "loss: 1.141878  [51200/60000]\n",
            "loss: 1.062178  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.1%, Avg loss: 1.082332 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqdoWByK3oxh",
        "outputId": "f1255f2f-c5ad-4b1b-d64e-d21e91336804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load model\n",
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB0EWHe24DXZ",
        "outputId": "b1cb826f-e321-4e10-f176-e761de2fc0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRHA5ZZP4HEJ",
        "outputId": "fffed502-2856-4b61-a768-0b60617527ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7zvhooAy4KUJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}